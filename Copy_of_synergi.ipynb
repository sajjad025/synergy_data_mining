{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of synergi.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKjhPlzgpTkk",
        "outputId": "f4c32fd5-2e18-4061-8bbb-4d03a80ebf32"
      },
      "source": [
        "!wget http://www.bioinf.jku.at/software/DeepSynergy/data_test_fold0_tanh.p.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-08 14:42:47--  http://www.bioinf.jku.at/software/DeepSynergy/data_test_fold0_tanh.p.gz\n",
            "Resolving www.bioinf.jku.at (www.bioinf.jku.at)... 140.78.90.4\n",
            "Connecting to www.bioinf.jku.at (www.bioinf.jku.at)|140.78.90.4|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3996502965 (3.7G) [application/x-gzip]\n",
            "Saving to: ‘data_test_fold0_tanh.p.gz’\n",
            "\n",
            "data_test_fold0_tan 100%[===================>]   3.72G  35.8MB/s    in 70s     \n",
            "\n",
            "2021-07-08 14:43:57 (54.2 MB/s) - ‘data_test_fold0_tanh.p.gz’ saved [3996502965/3996502965]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX7_ISh52yLp"
      },
      "source": [
        "import tensorflow as tf\n",
        "import gzip\n",
        "import pickle\n",
        "import os\n",
        "tf.random.set_seed(334)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X_HsAjo6jiQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa265f7e-a0a9-4928-cb91-d964f317c502"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8QhiRp32rR-"
      },
      "source": [
        "file = gzip.open('data_test_fold0_tanh.p.gz', 'rb')\n",
        "\n",
        "X_tr, X_val, X_train, X_test, y_tr, y_val, y_train, y_test = pickle.load(file)\n",
        "\n",
        "del X_tr\n",
        "del y_tr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4_-hqhFwQNT"
      },
      "source": [
        "#creating the model\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(8846, )),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Dense(1024, activation='relu'),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Dense(512, activation='relu'),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "\n",
        "#compiling the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='mean_squared_error',\n",
        "              metrics=['mse'],\n",
        "              run_eagerly=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ebUxPQu2LnX",
        "outputId": "3db4d2cb-c0df-4961-ad47-9deb0f494ca7"
      },
      "source": [
        "count=0\n",
        "best, _ = model.evaluate(X_test, y_test)\n",
        "while 1:\n",
        "  model.fit(X_train, y_train, epochs=5)\n",
        "  count += 1\n",
        "  print(\"test result:\")\n",
        "  loss, _ = model.evaluate(X_test, y_test)\n",
        "  if loss < best:\n",
        "    print('best model updated! loss it now', loss)\n",
        "    model.save('/gdrive/My Drive/best_model.h5')\n",
        "    best = loss\n",
        "  print(\"epoch count:\",count)\n",
        "  if count%5 == 0:\n",
        "    key=input(\"Do you want continue? y/n or(every thing)\")\n",
        "    if key!='y':\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "285/285 [==============================] - 4s 4ms/step - loss: 285.6067 - mse: 285.6067\n",
            "Epoch 1/10\n",
            "1157/1157 [==============================] - 28s 23ms/step - loss: 278.8878 - mse: 278.8878\n",
            "Epoch 2/10\n",
            "1157/1157 [==============================] - 27s 24ms/step - loss: 255.3741 - mse: 255.3741\n",
            "Epoch 3/10\n",
            "1157/1157 [==============================] - 27s 24ms/step - loss: 234.3993 - mse: 234.3993\n",
            "Epoch 4/10\n",
            "1157/1157 [==============================] - 27s 23ms/step - loss: 227.2825 - mse: 227.2825\n",
            "Epoch 5/10\n",
            "1157/1157 [==============================] - 27s 24ms/step - loss: 204.8289 - mse: 204.8289\n",
            "Epoch 6/10\n",
            "1157/1157 [==============================] - 27s 23ms/step - loss: 188.4697 - mse: 188.4697\n",
            "Epoch 7/10\n",
            "1157/1157 [==============================] - 27s 24ms/step - loss: 184.4144 - mse: 184.4144\n",
            "Epoch 8/10\n",
            "1157/1157 [==============================] - 28s 24ms/step - loss: 175.5204 - mse: 175.5204\n",
            "Epoch 9/10\n",
            "1157/1157 [==============================] - 28s 24ms/step - loss: 164.7840 - mse: 164.7840\n",
            "Epoch 10/10\n",
            "1157/1157 [==============================] - 27s 24ms/step - loss: 157.0882 - mse: 157.0882\n",
            "test result:\n",
            "285/285 [==============================] - 4s 15ms/step - loss: 2048.7876 - mse: 2048.7876\n",
            "epoch count: 1\n",
            "Epoch 1/10\n",
            "1157/1157 [==============================] - 22s 19ms/step - loss: 163.1492 - mse: 163.1492\n",
            "Epoch 2/10\n",
            "1157/1157 [==============================] - 21s 19ms/step - loss: 151.4986 - mse: 151.4986\n",
            "Epoch 3/10\n",
            "1157/1157 [==============================] - 21s 18ms/step - loss: 146.3773 - mse: 146.3773\n",
            "Epoch 4/10\n",
            "1157/1157 [==============================] - 21s 19ms/step - loss: 141.1137 - mse: 141.1137\n",
            "Epoch 5/10\n",
            "1157/1157 [==============================] - 21s 18ms/step - loss: 134.4667 - mse: 134.4667\n",
            "Epoch 6/10\n",
            "1157/1157 [==============================] - 21s 19ms/step - loss: 135.7359 - mse: 135.7359\n",
            "Epoch 7/10\n",
            "1157/1157 [==============================] - 22s 19ms/step - loss: 131.2917 - mse: 131.2917\n",
            "Epoch 8/10\n",
            "1157/1157 [==============================] - 21s 19ms/step - loss: 126.3273 - mse: 126.3273\n",
            "Epoch 9/10\n",
            "1157/1157 [==============================] - 21s 19ms/step - loss: 130.5523 - mse: 130.5523\n",
            "Epoch 10/10\n",
            "1157/1157 [==============================] - 22s 19ms/step - loss: 123.2083 - mse: 123.2083\n",
            "test result:\n",
            "285/285 [==============================] - 2s 8ms/step - loss: 336.6557 - mse: 336.6557\n",
            "epoch count: 2\n",
            "Epoch 1/10\n",
            "1157/1157 [==============================] - 13s 12ms/step - loss: 115.7819 - mse: 115.7819\n",
            "Epoch 2/10\n",
            "1157/1157 [==============================] - 13s 11ms/step - loss: 118.9361 - mse: 118.9361\n",
            "Epoch 3/10\n",
            "1157/1157 [==============================] - 13s 11ms/step - loss: 113.6273 - mse: 113.6273\n",
            "Epoch 4/10\n",
            "1157/1157 [==============================] - 13s 11ms/step - loss: 111.2141 - mse: 111.2141\n",
            "Epoch 5/10\n",
            "1157/1157 [==============================] - 13s 11ms/step - loss: 112.2648 - mse: 112.2648\n",
            "Epoch 6/10\n",
            "1157/1157 [==============================] - 13s 11ms/step - loss: 109.2657 - mse: 109.2657\n",
            "Epoch 7/10\n",
            "1157/1157 [==============================] - 13s 11ms/step - loss: 105.3214 - mse: 105.3214\n",
            "Epoch 8/10\n",
            "1157/1157 [==============================] - 13s 11ms/step - loss: 104.6372 - mse: 104.6372\n",
            "Epoch 9/10\n",
            "1157/1157 [==============================] - 13s 11ms/step - loss: 106.4116 - mse: 106.4116\n",
            "Epoch 10/10\n",
            "1157/1157 [==============================] - 13s 11ms/step - loss: 99.1846 - mse: 99.1846\n",
            "test result:\n",
            "285/285 [==============================] - 1s 5ms/step - loss: 1374.4673 - mse: 1374.4673\n",
            "epoch count: 3\n",
            "Epoch 1/10\n",
            "1157/1157 [==============================] - 11s 10ms/step - loss: 100.6017 - mse: 100.6017\n",
            "Epoch 2/10\n",
            "1157/1157 [==============================] - 11s 10ms/step - loss: 98.9655 - mse: 98.9655\n",
            "Epoch 3/10\n",
            "1157/1157 [==============================] - 11s 10ms/step - loss: 98.7991 - mse: 98.7991\n",
            "Epoch 4/10\n",
            "1157/1157 [==============================] - 11s 10ms/step - loss: 97.4514 - mse: 97.4514\n",
            "Epoch 5/10\n",
            "1157/1157 [==============================] - 11s 10ms/step - loss: 97.5146 - mse: 97.5146\n",
            "Epoch 6/10\n",
            "1157/1157 [==============================] - 11s 10ms/step - loss: 93.7607 - mse: 93.7607\n",
            "Epoch 7/10\n",
            "1157/1157 [==============================] - 11s 10ms/step - loss: 93.3229 - mse: 93.3229\n",
            "Epoch 8/10\n",
            "1157/1157 [==============================] - 11s 10ms/step - loss: 92.2551 - mse: 92.2551\n",
            "Epoch 9/10\n",
            "1157/1157 [==============================] - 11s 10ms/step - loss: 94.5182 - mse: 94.5182\n",
            "Epoch 10/10\n",
            "1157/1157 [==============================] - 11s 10ms/step - loss: 90.2403 - mse: 90.2403\n",
            "test result:\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 264.9632 - mse: 264.9632\n",
            "best model updated! loss it now 264.96319580078125\n",
            "epoch count: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhB24vclh6sG",
        "outputId": "8621be54-5a56-4938-f4cd-ff3f96b21b8c"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=95, validation_data = (X_val, y_val))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/95\n",
            "1157/1157 [==============================] - 42s 34ms/step - loss: 431.1185 - mse: 431.1185 - val_loss: 342.2583 - val_mse: 342.2583\n",
            "Epoch 2/95\n",
            "1157/1157 [==============================] - 41s 35ms/step - loss: 373.9376 - mse: 373.9376 - val_loss: 346.7945 - val_mse: 346.7945\n",
            "Epoch 3/95\n",
            "1157/1157 [==============================] - 41s 36ms/step - loss: 337.3473 - mse: 337.3473 - val_loss: 260.4380 - val_mse: 260.4380\n",
            "Epoch 4/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 300.8743 - mse: 300.8743 - val_loss: 225.5896 - val_mse: 225.5896\n",
            "Epoch 5/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 278.3470 - mse: 278.3470 - val_loss: 223.6873 - val_mse: 223.6873\n",
            "Epoch 6/95\n",
            "1157/1157 [==============================] - 41s 35ms/step - loss: 257.5017 - mse: 257.5017 - val_loss: 206.4746 - val_mse: 206.4746\n",
            "Epoch 7/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 235.8334 - mse: 235.8334 - val_loss: 242.7530 - val_mse: 242.7530\n",
            "Epoch 8/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 221.6561 - mse: 221.6561 - val_loss: 227.0738 - val_mse: 227.0738\n",
            "Epoch 9/95\n",
            "1157/1157 [==============================] - 40s 35ms/step - loss: 202.0744 - mse: 202.0744 - val_loss: 214.4168 - val_mse: 214.4168\n",
            "Epoch 10/95\n",
            "1157/1157 [==============================] - 40s 35ms/step - loss: 190.2183 - mse: 190.2183 - val_loss: 195.9763 - val_mse: 195.9763\n",
            "Epoch 11/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 178.4864 - mse: 178.4864 - val_loss: 280.1464 - val_mse: 280.1464\n",
            "Epoch 12/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 183.6992 - mse: 183.6992 - val_loss: 180.4548 - val_mse: 180.4548\n",
            "Epoch 13/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 162.8209 - mse: 162.8209 - val_loss: 173.0168 - val_mse: 173.0168\n",
            "Epoch 14/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 160.1234 - mse: 160.1234 - val_loss: 151.5948 - val_mse: 151.5948\n",
            "Epoch 15/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 153.9747 - mse: 153.9747 - val_loss: 141.4572 - val_mse: 141.4572\n",
            "Epoch 16/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 147.2017 - mse: 147.2017 - val_loss: 161.6262 - val_mse: 161.6262\n",
            "Epoch 17/95\n",
            "1157/1157 [==============================] - 41s 35ms/step - loss: 141.9638 - mse: 141.9638 - val_loss: 344.0642 - val_mse: 344.0642\n",
            "Epoch 18/95\n",
            "1157/1157 [==============================] - 41s 35ms/step - loss: 140.2712 - mse: 140.2712 - val_loss: 213.9793 - val_mse: 213.9793\n",
            "Epoch 19/95\n",
            "1157/1157 [==============================] - 41s 35ms/step - loss: 131.1971 - mse: 131.1971 - val_loss: 123.6868 - val_mse: 123.6868\n",
            "Epoch 20/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 132.0387 - mse: 132.0387 - val_loss: 146.6130 - val_mse: 146.6130\n",
            "Epoch 21/95\n",
            "1157/1157 [==============================] - 40s 35ms/step - loss: 127.9845 - mse: 127.9845 - val_loss: 188.2549 - val_mse: 188.2549\n",
            "Epoch 22/95\n",
            "1157/1157 [==============================] - 41s 35ms/step - loss: 123.2103 - mse: 123.2103 - val_loss: 115.3902 - val_mse: 115.3902\n",
            "Epoch 23/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 119.1010 - mse: 119.1010 - val_loss: 126.0154 - val_mse: 126.0154\n",
            "Epoch 24/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 118.2041 - mse: 118.2041 - val_loss: 114.6657 - val_mse: 114.6657\n",
            "Epoch 25/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 118.6054 - mse: 118.6054 - val_loss: 118.6034 - val_mse: 118.6034\n",
            "Epoch 26/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 114.6289 - mse: 114.6289 - val_loss: 120.6309 - val_mse: 120.6309\n",
            "Epoch 27/95\n",
            "1157/1157 [==============================] - 40s 35ms/step - loss: 112.4911 - mse: 112.4911 - val_loss: 103.0923 - val_mse: 103.0923\n",
            "Epoch 28/95\n",
            "1157/1157 [==============================] - 40s 35ms/step - loss: 110.5832 - mse: 110.5832 - val_loss: 132.7124 - val_mse: 132.7124\n",
            "Epoch 29/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 106.4591 - mse: 106.4591 - val_loss: 119.1188 - val_mse: 119.1188\n",
            "Epoch 30/95\n",
            "1157/1157 [==============================] - 40s 35ms/step - loss: 104.2946 - mse: 104.2946 - val_loss: 109.8983 - val_mse: 109.8983\n",
            "Epoch 31/95\n",
            "1157/1157 [==============================] - 40s 35ms/step - loss: 102.9755 - mse: 102.9755 - val_loss: 88.7064 - val_mse: 88.7064\n",
            "Epoch 32/95\n",
            "1157/1157 [==============================] - 40s 35ms/step - loss: 101.0107 - mse: 101.0107 - val_loss: 104.4680 - val_mse: 104.4680\n",
            "Epoch 33/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 103.0042 - mse: 103.0042 - val_loss: 102.7621 - val_mse: 102.7621\n",
            "Epoch 34/95\n",
            "1157/1157 [==============================] - 41s 35ms/step - loss: 98.3265 - mse: 98.3265 - val_loss: 99.4088 - val_mse: 99.4088\n",
            "Epoch 35/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 97.9314 - mse: 97.9314 - val_loss: 120.0158 - val_mse: 120.0158\n",
            "Epoch 36/95\n",
            "1157/1157 [==============================] - 40s 35ms/step - loss: 98.1983 - mse: 98.1983 - val_loss: 92.6673 - val_mse: 92.6673\n",
            "Epoch 37/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 95.1833 - mse: 95.1833 - val_loss: 108.1961 - val_mse: 108.1961\n",
            "Epoch 38/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 94.3541 - mse: 94.3541 - val_loss: 97.6265 - val_mse: 97.6265\n",
            "Epoch 39/95\n",
            "1157/1157 [==============================] - 40s 35ms/step - loss: 95.1892 - mse: 95.1892 - val_loss: 99.2595 - val_mse: 99.2595\n",
            "Epoch 40/95\n",
            "1157/1157 [==============================] - 41s 35ms/step - loss: 92.8514 - mse: 92.8514 - val_loss: 98.4823 - val_mse: 98.4823\n",
            "Epoch 41/95\n",
            "1157/1157 [==============================] - 41s 35ms/step - loss: 90.9784 - mse: 90.9784 - val_loss: 95.6954 - val_mse: 95.6954\n",
            "Epoch 42/95\n",
            "1157/1157 [==============================] - 41s 35ms/step - loss: 89.2172 - mse: 89.2172 - val_loss: 89.5039 - val_mse: 89.5039\n",
            "Epoch 43/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 88.3939 - mse: 88.3939 - val_loss: 77.0479 - val_mse: 77.0479\n",
            "Epoch 44/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 87.0347 - mse: 87.0347 - val_loss: 73.0069 - val_mse: 73.0069\n",
            "Epoch 45/95\n",
            "1157/1157 [==============================] - 41s 35ms/step - loss: 86.3623 - mse: 86.3623 - val_loss: 87.2921 - val_mse: 87.2921\n",
            "Epoch 46/95\n",
            "1157/1157 [==============================] - 41s 35ms/step - loss: 86.4738 - mse: 86.4738 - val_loss: 90.5423 - val_mse: 90.5423\n",
            "Epoch 47/95\n",
            "1157/1157 [==============================] - 41s 35ms/step - loss: 86.2020 - mse: 86.2020 - val_loss: 79.9808 - val_mse: 79.9808\n",
            "Epoch 48/95\n",
            "1157/1157 [==============================] - 41s 35ms/step - loss: 84.0453 - mse: 84.0453 - val_loss: 112.5970 - val_mse: 112.5970\n",
            "Epoch 49/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 83.4203 - mse: 83.4203 - val_loss: 120.5797 - val_mse: 120.5797\n",
            "Epoch 50/95\n",
            "1157/1157 [==============================] - 41s 35ms/step - loss: 82.3511 - mse: 82.3511 - val_loss: 76.9814 - val_mse: 76.9814\n",
            "Epoch 51/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 82.1159 - mse: 82.1159 - val_loss: 73.8505 - val_mse: 73.8505\n",
            "Epoch 52/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 81.6264 - mse: 81.6264 - val_loss: 78.8989 - val_mse: 78.8989\n",
            "Epoch 53/95\n",
            "1157/1157 [==============================] - 39s 33ms/step - loss: 82.4693 - mse: 82.4693 - val_loss: 77.8760 - val_mse: 77.8760\n",
            "Epoch 54/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 80.7362 - mse: 80.7362 - val_loss: 71.6292 - val_mse: 71.6292\n",
            "Epoch 55/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 79.4958 - mse: 79.4958 - val_loss: 70.5670 - val_mse: 70.5670\n",
            "Epoch 56/95\n",
            "1157/1157 [==============================] - 41s 35ms/step - loss: 79.4834 - mse: 79.4834 - val_loss: 78.8190 - val_mse: 78.8190\n",
            "Epoch 57/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 79.4632 - mse: 79.4632 - val_loss: 67.3308 - val_mse: 67.3308\n",
            "Epoch 58/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 78.9284 - mse: 78.9284 - val_loss: 64.1688 - val_mse: 64.1688\n",
            "Epoch 59/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 77.2074 - mse: 77.2074 - val_loss: 66.5777 - val_mse: 66.5777\n",
            "Epoch 60/95\n",
            "1157/1157 [==============================] - 42s 36ms/step - loss: 76.6732 - mse: 76.6732 - val_loss: 69.8282 - val_mse: 69.8282\n",
            "Epoch 61/95\n",
            "1157/1157 [==============================] - 39s 33ms/step - loss: 76.1775 - mse: 76.1775 - val_loss: 62.9313 - val_mse: 62.9313\n",
            "Epoch 62/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 77.1489 - mse: 77.1489 - val_loss: 63.8902 - val_mse: 63.8902\n",
            "Epoch 63/95\n",
            "1157/1157 [==============================] - 41s 35ms/step - loss: 75.9816 - mse: 75.9816 - val_loss: 69.5649 - val_mse: 69.5649\n",
            "Epoch 64/95\n",
            "1157/1157 [==============================] - 41s 35ms/step - loss: 75.6424 - mse: 75.6424 - val_loss: 65.9692 - val_mse: 65.9692\n",
            "Epoch 65/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 75.1391 - mse: 75.1391 - val_loss: 65.3543 - val_mse: 65.3543\n",
            "Epoch 66/95\n",
            "1157/1157 [==============================] - 41s 35ms/step - loss: 74.0414 - mse: 74.0414 - val_loss: 66.5092 - val_mse: 66.5092\n",
            "Epoch 67/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 73.5098 - mse: 73.5098 - val_loss: 68.2141 - val_mse: 68.2141\n",
            "Epoch 68/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 74.6395 - mse: 74.6395 - val_loss: 70.7414 - val_mse: 70.7414\n",
            "Epoch 69/95\n",
            "1157/1157 [==============================] - 41s 35ms/step - loss: 73.8821 - mse: 73.8821 - val_loss: 69.3947 - val_mse: 69.3947\n",
            "Epoch 70/95\n",
            "1157/1157 [==============================] - 41s 35ms/step - loss: 71.9832 - mse: 71.9832 - val_loss: 66.7927 - val_mse: 66.7927\n",
            "Epoch 71/95\n",
            "1157/1157 [==============================] - 41s 35ms/step - loss: 73.9571 - mse: 73.9571 - val_loss: 69.4189 - val_mse: 69.4189\n",
            "Epoch 72/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 71.7319 - mse: 71.7319 - val_loss: 71.8021 - val_mse: 71.8021\n",
            "Epoch 73/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 71.0947 - mse: 71.0947 - val_loss: 75.4871 - val_mse: 75.4871\n",
            "Epoch 74/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 71.4242 - mse: 71.4242 - val_loss: 68.4438 - val_mse: 68.4438\n",
            "Epoch 75/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 70.3805 - mse: 70.3805 - val_loss: 86.9054 - val_mse: 86.9054\n",
            "Epoch 76/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 71.2031 - mse: 71.2031 - val_loss: 69.5470 - val_mse: 69.5470\n",
            "Epoch 77/95\n",
            "1157/1157 [==============================] - 41s 35ms/step - loss: 71.9114 - mse: 71.9114 - val_loss: 78.7744 - val_mse: 78.7744\n",
            "Epoch 78/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 70.3461 - mse: 70.3461 - val_loss: 65.7885 - val_mse: 65.7885\n",
            "Epoch 79/95\n",
            "1157/1157 [==============================] - 41s 35ms/step - loss: 70.4314 - mse: 70.4314 - val_loss: 65.8300 - val_mse: 65.8300\n",
            "Epoch 80/95\n",
            "1157/1157 [==============================] - 39s 33ms/step - loss: 70.3968 - mse: 70.3968 - val_loss: 62.7302 - val_mse: 62.7302\n",
            "Epoch 81/95\n",
            "1157/1157 [==============================] - 41s 35ms/step - loss: 70.1140 - mse: 70.1140 - val_loss: 94.8388 - val_mse: 94.8388\n",
            "Epoch 82/95\n",
            "1157/1157 [==============================] - 41s 35ms/step - loss: 68.9393 - mse: 68.9393 - val_loss: 67.1790 - val_mse: 67.1790\n",
            "Epoch 83/95\n",
            "1157/1157 [==============================] - 41s 35ms/step - loss: 68.9601 - mse: 68.9601 - val_loss: 85.3662 - val_mse: 85.3662\n",
            "Epoch 84/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 69.3626 - mse: 69.3626 - val_loss: 65.7925 - val_mse: 65.7925\n",
            "Epoch 85/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 68.0003 - mse: 68.0003 - val_loss: 63.4318 - val_mse: 63.4318\n",
            "Epoch 86/95\n",
            "1157/1157 [==============================] - 41s 35ms/step - loss: 68.5982 - mse: 68.5982 - val_loss: 62.0796 - val_mse: 62.0796\n",
            "Epoch 87/95\n",
            "1157/1157 [==============================] - 38s 33ms/step - loss: 67.9364 - mse: 67.9364 - val_loss: 63.9613 - val_mse: 63.9613\n",
            "Epoch 88/95\n",
            "1157/1157 [==============================] - 41s 35ms/step - loss: 67.6737 - mse: 67.6737 - val_loss: 75.5753 - val_mse: 75.5753\n",
            "Epoch 89/95\n",
            "1157/1157 [==============================] - 41s 36ms/step - loss: 67.4636 - mse: 67.4636 - val_loss: 65.4338 - val_mse: 65.4338\n",
            "Epoch 90/95\n",
            "1157/1157 [==============================] - 39s 33ms/step - loss: 67.1225 - mse: 67.1225 - val_loss: 65.6878 - val_mse: 65.6878\n",
            "Epoch 91/95\n",
            "1157/1157 [==============================] - 39s 34ms/step - loss: 66.6940 - mse: 66.6940 - val_loss: 65.8525 - val_mse: 65.8525\n",
            "Epoch 92/95\n",
            "1157/1157 [==============================] - 42s 37ms/step - loss: 66.7598 - mse: 66.7598 - val_loss: 69.4042 - val_mse: 69.4042\n",
            "Epoch 93/95\n",
            "1157/1157 [==============================] - 46s 40ms/step - loss: 66.4326 - mse: 66.4326 - val_loss: 72.3255 - val_mse: 72.3255\n",
            "Epoch 94/95\n",
            "1157/1157 [==============================] - 43s 37ms/step - loss: 67.0980 - mse: 67.0980 - val_loss: 70.9926 - val_mse: 70.9926\n",
            "Epoch 95/95\n",
            "1157/1157 [==============================] - 45s 39ms/step - loss: 67.4897 - mse: 67.4897 - val_loss: 91.0734 - val_mse: 91.0734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f43bdc48650>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJl-l1iA2M4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f070a6a6-9c5b-46ca-f404-4518e21099eb"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "285/285 [==============================] - 4s 4ms/step - loss: 229.8353 - mse: 229.8353\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[229.83531188964844, 229.83531188964844]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFtlC1GIzEmO"
      },
      "source": [
        "model.save('/gdrive/My Drive/best_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wFLQgrh8faD"
      },
      "source": [
        "#load model\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('/gdrive/My Drive/best_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXql4iwVYLh2",
        "outputId": "f34fa639-6af0-4699-a5c9-77982e7923ec"
      },
      "source": [
        "\n",
        "y_pred= model.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "print('RMSE:', rmse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 15.160319842643142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAGcS2P-mBQ_",
        "outputId": "1bc1a6e8-3530-4e86-f970-3bd0919ffeeb"
      },
      "source": [
        "from scipy.stats import pearsonr\n",
        "y_n=np.reshape(y_pred,(9108,))\n",
        "pearson_r = pearsonr(y_n,y_test)\n",
        "print(\"Pearson\\'s r:\", pearson_r)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pearson's r: (0.6856798816419686, 0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCXg2XO7oTgh",
        "outputId": "aff3c1a8-1d4b-4c02-f78c-b7307d0ea58f"
      },
      "source": [
        "y_n=np.reshape(y_pred,(9108,))\n",
        "y_n[0:5]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-3.2676618 ,  0.31541526,  3.6097574 , -2.1480434 , -6.6353416 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    }
  ]
}